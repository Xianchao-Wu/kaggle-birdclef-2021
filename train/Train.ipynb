{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa as lb\n",
    "import librosa.display as lbd\n",
    "import soundfile as sf\n",
    "from  soundfile import SoundFile\n",
    "import pandas as pd\n",
    "from  IPython.display import Audio\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import librosa\n",
    "from torchvision import transforms\n",
    "from torch import nn, optim\n",
    "from  torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.swa_utils import AveragedModel, SWALR\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from resnest.torch import resnest50, resnest101\n",
    "from torch.optim import Adam, SGD, AdamW\n",
    "from common import *\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n",
    "from matplotlib import pyplot as plt\n",
    "from torchlibrosa.augmentation import SpecAugmentation\n",
    "import os, random, gc\n",
    "import re, time, json\n",
    "from  ast import literal_eval\n",
    "import timm\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\n",
    "from IPython.display import Audio\n",
    "from sklearn.metrics import label_ranking_average_precision_score\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from efficientnet_pytorch import EfficientNet\n",
    "import pretrainedmodels\n",
    "import resnest.torch as resnest_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define all the hyperparms with their values\n",
    "class CFG:\n",
    "    debug=False\n",
    "    num_classes=397\n",
    "    model_name='resnest50'\n",
    "    augs = ['white_noise','pink_noise','bandpass_noise', 'upper']\n",
    "    num_workers=0\n",
    "    batch_size=64\n",
    "    epochs=60\n",
    "    n_mels=128\n",
    "    len_check=281\n",
    "    exp_name='augs_mix3_3_col_cor_60'\n",
    "    scheduler='CosineAnnealingLR' # ['ReduceLROnPlateau', 'CosineAnnealingLR', 'CosineAnnealingWarmRestarts']\n",
    "#     factor=0.4 # ReduceLROnPlateau\n",
    "#     patience=0 # ReduceLROnPlateau\n",
    "#     eps=1e-6 # ReduceLROnPlateau\n",
    "    T_max=80 # CosineAnnealingLR\n",
    "#     T_0=20 #osineAnnealingWarmRestarts\n",
    "    pretrained=True\n",
    "    checkpoint=False\n",
    "    save=True\n",
    "    train=True\n",
    "    base_lr=0.001 \n",
    "    min_lr=1e-6\n",
    "    n_fold=10\n",
    "    trn_fold=[0]\n",
    "    seed=42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = Path(r\"Birdcall\")\n",
    "MODEL_ROOT = Path(r\"Birdcall\\models\")\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "OUTPUT_DIR = f\"Birdcall/models/{CFG.model_name}_{CFG.exp_name}/fold{CFG.trn_fold}\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pd.read_csv(r\"Birdcall\\meta.csv\")\n",
    "meta = meta.fillna('')\n",
    "\n",
    "meta['labels_bg'] = meta['labels_bg'].replace({'rocpig1 solsan whtdov':'rocpig solsan whtdov'})\n",
    "meta['labels_bg'] = meta['labels_bg'].replace({'rocpig1 grtgra':'rocpig grtgra'})\n",
    "meta['labels_bg'] = meta['labels_bg'].replace({'rewbla rocpig1 cangoo saypho killde amerob':'rewbla rocpig cangoo saypho killde amerob'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta[meta['labels_bg'].str.contains('rocpig1')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(r\"Birdcall\\train_metadata.csv\")\n",
    "\n",
    "LABEL_IDS = {label: label_id for label_id,label in enumerate(sorted(df_train[\"primary_label\"].unique()))}\n",
    "INV_LABEL_IDS = {val: key for key,val in LABEL_IDS.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 fold-split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = meta.copy()\n",
    "Fold = StratifiedKFold(n_splits=CFG.n_fold, shuffle=True, random_state=CFG.seed)\n",
    "for n, (train_index, val_index) in enumerate(Fold.split(folds, folds['bird'])):\n",
    "    folds.loc[val_index, 'fold'] = int(n)\n",
    "folds['fold'] = folds['fold'].astype(int)\n",
    "print(folds.groupby(['fold']).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(name, num_classes=CFG.num_classes):\n",
    "    \"\"\"\n",
    "    Loads a pretrained model. \n",
    "    Supports ResNest, ResNext-wsl, EfficientNet, ResNext and ResNet.\n",
    "\n",
    "    Arguments:\n",
    "        name {str} -- Name of the model to load\n",
    "\n",
    "    Keyword Arguments:\n",
    "        num_classes {int} -- Number of classes to use (default: {1})\n",
    "\n",
    "    Returns:\n",
    "        torch model -- Pretrained model\n",
    "    \"\"\"\n",
    "    if \"resnest\" in name:\n",
    "        model = getattr(resnest_torch, name)(pretrained=True)\n",
    "    elif \"wsl\" in name:\n",
    "        model = torch.hub.load(\"facebookresearch/WSL-Images\", name)\n",
    "    elif name.startswith(\"resnext\") or  name.startswith(\"resnet\"):\n",
    "        model = torch.hub.load(\"pytorch/vision:v0.6.0\", name, pretrained=True)\n",
    "    elif name.startswith(\"densenet\"):\n",
    "        model = getattr(timm.models.densenet, name)(pretrained=True)\n",
    "    elif name.startswith(\"tf_efficientnet_b\"):\n",
    "        model = getattr(timm.models.efficientnet, name)(pretrained=True)\n",
    "    elif \"efficientnet-b\" in name:\n",
    "        model = EfficientNet.from_pretrained(name)\n",
    "    else:\n",
    "        model = pretrainedmodels.__dict__[name](pretrained='imagenet')\n",
    "\n",
    "    if hasattr(model, \"fc\"):\n",
    "        nb_ft = model.fc.in_features\n",
    "        model.fc = nn.Linear(nb_ft, num_classes)\n",
    "    elif hasattr(model, \"_fc\"):\n",
    "        nb_ft = model._fc.in_features\n",
    "        model._fc = nn.Linear(nb_ft, num_classes)\n",
    "    elif hasattr(model, \"classifier\"):\n",
    "        nb_ft = model.classifier.in_features\n",
    "        model.classifier = nn.Linear(nb_ft, num_classes)\n",
    "    elif hasattr(model, \"last_linear\"):\n",
    "        nb_ft = model.last_linear.in_features\n",
    "        model.last_linear = nn.Linear(nb_ft, num_classes)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data on RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(df):\n",
    "    def load_row(row):\n",
    "        # impath = TRAIN_IMAGES_ROOT/f\"{row.primary_label}/{row.filename}.npy\"\n",
    "        return row.file, np.load(str(row.impath))\n",
    "    pool = joblib.Parallel(4)\n",
    "    mapper = joblib.delayed(load_row)\n",
    "    tasks = [mapper(row) for row in df.itertuples(False)]\n",
    "    res = pool(tqdm(tasks))\n",
    "    res = dict(res)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_image_store = load_data(meta)\n",
    "len(audio_image_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_power(images, power = 1.5, c= 0.7):\n",
    "    images = images - images.min()\n",
    "    images = images/(images.max()+0.0000001)\n",
    "    images = images**(random.random()*power + c)\n",
    "    return images\n",
    "\n",
    "def mono_to_color(X: np.ndarray,len_check, mean=0.5, std=0.5, eps=1e-6):\n",
    "    trans = transforms.Compose([transforms.ToPILImage(),\n",
    "                                        transforms.Resize([CFG.n_mels, len_check]), transforms.ToTensor(),\n",
    "                                        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])])\n",
    "    X = np.stack([X, X, X], axis=-1)\n",
    "    V = (255 * X).astype(np.uint8)\n",
    "    V = (trans(V)+1)/2\n",
    "    return V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BirdClefDataset(Dataset):\n",
    "    def __init__(self, audio_image_store,bird_list,LABEL_IDS,INV_LABEL_IDS,is_train):\n",
    "        # Initialize the list of melspectrograms\n",
    "        self.audio_image_store = audio_image_store\n",
    "        self.bird_list = bird_list\n",
    "        self.n_mels = CFG.n_mels\n",
    "        self.noise = pd.read_csv(r\"Birdcall\\no_call.csv\")\n",
    "        self.len_check = CFG.len_check\n",
    "        self.count_bird = CFG.num_classes\n",
    "        self.augs = CFG.augs\n",
    "        self.BIRD_CODE = LABEL_IDS\n",
    "        self.INV_BIRD_CODE = INV_LABEL_IDS\n",
    "        self.stop_border = 0.3 # Probability of stopping mixing\n",
    "        self.level_noise = 0.05 # level noise\n",
    "        self.div_coef = 100 # signal amplification during mixing\n",
    "        self.is_train = is_train\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.bird_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.is_train:\n",
    "            idx2 = random.randint(0, len(self.bird_list)-1) # Second file\n",
    "            idx3 = random.randint(0, len(self.bird_list)-1) # Third file not added as of now\n",
    "\n",
    "            y = torch.zeros(self.count_bird)\n",
    "            birds, background = [],[]\n",
    "\n",
    "            # Length of the segment\n",
    "            self.len_check = random.randint(281-14, 281+21)\n",
    "            #self.len_chack = self.hp.len_chack[0]\n",
    "            \n",
    "            images = np.zeros((self.n_mels, self.len_check)).astype(np.float32)     \n",
    "            for i,idy in enumerate([idx,idx2,idx3]):\n",
    "                # Choosing a record with a bird \n",
    "                sample = self.bird_list.iloc[idy]\n",
    "                # Uploading a record with a bird \n",
    "                mel = self.audio_image_store[sample.file]\n",
    "                mel = mel[np.random.choice(len(mel))]\n",
    "                # Birds in the file\n",
    "                labels_bird = sample.bird.split()\n",
    "                for bird in labels_bird:\n",
    "                    if not bird in birds and bird != CFG.num_classes:\n",
    "                        birds.append(self.BIRD_CODE[bird])\n",
    "\n",
    "                # Birds in the background   \n",
    "                if sample.labels_bg:\n",
    "                    labels_bg = sample.labels_bg.split()\n",
    "                    for bg in labels_bg:\n",
    "                        if not bg in background:\n",
    "                            background.append(self.BIRD_CODE[bg])\n",
    "\n",
    "                # Select the piece that contains the sound \n",
    "                if mel.shape[1]>self.len_check: \n",
    "                    start = random.randint(0, mel.shape[1] - self.len_check - 1)\n",
    "                    mel = mel[:, start : start + random.randint(self.len_check-14, self.len_check)]\n",
    "                else:\n",
    "                    len_zero = random.randint(0, self.len_check-mel.shape[1])\n",
    "                    mel = np.concatenate((np.zeros((self.n_mels,len_zero)),mel), axis=1)\n",
    "\n",
    "                mel = np.concatenate((mel,np.zeros((self.n_mels,self.len_check-mel.shape[1]))), axis=1)\n",
    "\n",
    "                # Change the contrast\n",
    "                mel = random_power(mel, power = 3, c= 0.5)\n",
    "                #mel = librosa.power_to_db(mel.astype(np.float32), ref=np.max)\n",
    "                #mel = (mel+80)/80\n",
    "\n",
    "                # Mix the signal\n",
    "                images = images + mel*(random.random() * self.div_coef + 1)\n",
    "\n",
    "                # Abort accidentally\n",
    "                if random.random()<self.stop_border:\n",
    "                    break\n",
    "\n",
    "            # Add a different sound with second bird... \n",
    "            idy = random.randint(0, len(self.noise)-1)\n",
    "            sample = self.noise.loc[idy, :]\n",
    "            mel = np.load(sample.impath)\n",
    "            mel = mel[np.random.choice(len(mel))]\n",
    "            mel = np.concatenate((np.zeros((self.n_mels,self.len_check)),mel), axis=1)\n",
    "            mel = np.concatenate((mel,np.zeros((self.n_mels,self.len_check))), axis=1)\n",
    "            start = random.randint(0, mel.shape[1] - self.len_check - 1)\n",
    "            mel = mel[:, start : start + self.len_check]\n",
    "\n",
    "            mel = random_power(mel)\n",
    "#             mel = lb.power_to_db(mel.astype(np.float32), ref=np.max)\n",
    "#             mel = (mel+80)/80\n",
    "            images = images + mel/(mel.max()+0.0000001)*(random.random()*1+0.5)*images.max()\n",
    "            \n",
    "            # In db and normalize\n",
    "#             images = librosa.power_to_db(images.astype(np.float32), ref=np.max)\n",
    "#             images = (images+80)/80\n",
    "\n",
    "            # Add noise\n",
    "            # Add white noise \n",
    "            if random.random()<0.7 and 'white_noise' in self.augs:\n",
    "#                 print('white noise')\n",
    "                images = images + (np.random.sample((self.n_mels,self.len_check)).astype(np.float32)+9) * images.mean() * self.level_noise * (np.random.sample() + 0.3)\n",
    "\n",
    "            # Add pink noise\n",
    "            if random.random()<0.7 and 'pink_noise' in self.augs:\n",
    "#                 print('Pink Noise')\n",
    "                r = random.randint(1,self.n_mels)\n",
    "                pink_noise = np.array([np.concatenate((1 - np.arange(r)/r,np.zeros(self.n_mels-r)))]).T\n",
    "                images = images + (np.random.sample((self.n_mels,self.len_check)).astype(np.float32)+9) * 2  * images.mean() * self.level_noise * (np.random.sample() + 0.3)\n",
    "\n",
    "            # Add bandpass noise\n",
    "            if random.random()<0.7 and 'bandpass_noise' in self.augs:\n",
    "#                 print('bandpass noise')\n",
    "                a = random.randint(0, self.n_mels//2)\n",
    "                b = random.randint(a+20, self.n_mels)\n",
    "                images[a:b,:] = images[a:b,:] + (np.random.sample((b-a,self.len_check)).astype(np.float32)+9) * 0.1 * images.mean() * self.level_noise  * (np.random.sample() + 0.3)\n",
    "\n",
    "\n",
    "            # Lower the upper frequencies\n",
    "            if random.random()<0.5 and 'upper' in self.augs:\n",
    "#                 print('upper')\n",
    "                images = images - images.min()\n",
    "                r = random.randint(self.n_mels//2,self.n_mels)\n",
    "                x = random.random()/2\n",
    "                pink_noise = np.array([np.concatenate((1-np.arange(r)*x/r,np.zeros(self.n_mels-r)-x+1))]).T\n",
    "                images = images*pink_noise\n",
    "                images = images/images.max()\n",
    "\n",
    "            # Change the contrast\n",
    "    #         print('random power')\n",
    "            images = random_power(images, power = 2, c= 0.7)\n",
    "\n",
    "            # Expand to 3 channels\n",
    "            #images = torch.from_numpy(np.stack([images, images, images])).float()\n",
    "            images = mono_to_color(images,281)\n",
    "\n",
    "            # Draw pictures\n",
    "            if random.random()<0.00001:\n",
    "                img = images.numpy()\n",
    "                img = img - img.min()\n",
    "                img = img/img.max()\n",
    "                img = np.moveaxis(img, 0, 2)\n",
    "                imgplot = plt.imshow(img)\n",
    "                plt.savefig(\"Birdcall/images/\"+(\"_\".join(self.INV_BIRD_CODE[x] for x in birds))+'_train_'+sample.file+'.png')    \n",
    "\n",
    "            # The background is 0.3, and the marked bird is 1\n",
    "            for bird in background:\n",
    "                if bird < len(y):\n",
    "                    y[bird]=0.3\n",
    "            for bird in birds:\n",
    "                #if not bird==264:\n",
    "                y[bird]=1\n",
    "            return images, y\n",
    "        \n",
    "        else:\n",
    "            y = torch.zeros(self.count_bird)\n",
    "            birds, background = [],[]\n",
    "            \n",
    "            sample = self.bird_list.iloc[idx]\n",
    "            mel = self.audio_image_store[sample.file]\n",
    "            mel = mel[np.random.choice(len(mel))]\n",
    "            images = mel\n",
    "            # Birds in the file\n",
    "            labels_bird = sample.bird.split()\n",
    "            for bird in labels_bird:\n",
    "                if not bird in birds and bird != CFG.num_classes:\n",
    "                    birds.append(self.BIRD_CODE[bird])\n",
    "                    \n",
    "            # Birds in the background   \n",
    "            if sample.labels_bg:\n",
    "                labels_bg = sample.labels_bg.split()\n",
    "                for bg in labels_bg:\n",
    "                    if not bg in background:\n",
    "                        background.append(self.BIRD_CODE[bg])\n",
    "            \n",
    "            images = random_power(images, power = 2, c= 0.7)\n",
    "            images = mono_to_color(images,281)\n",
    "            # Draw pictures\n",
    "            if random.random()<0.00001:\n",
    "                img = images.numpy()\n",
    "                img = img - img.min()\n",
    "                img = img/img.max()\n",
    "                img = np.moveaxis(img, 0, 2)\n",
    "                imgplot = plt.imshow(img)\n",
    "                plt.savefig(\"E:/Birdcall/images/\"+(\"_\".join(self.INV_BIRD_CODE[x] for x in birds))+'_valid_'+sample.file+'.png')    \n",
    "            \n",
    "            # The background is 0.3, and the marked bird is 1\n",
    "            for bird in background:\n",
    "                if bird < len(y):\n",
    "                    y[bird]=0.3\n",
    "            for bird in birds:\n",
    "                #if not bird==264:\n",
    "                y[bird]=1\n",
    "            return images, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(net, criterion, valid_loader):\n",
    "    net.eval()\n",
    "\n",
    "    os, y = [], []\n",
    "    valid_loader = tqdm(valid_loader, leave = False, total=len(valid_loader))\n",
    "\n",
    "    for icount, (xb, yb) in  enumerate(valid_loader):\n",
    "\n",
    "        y.append(yb.to(DEVICE))\n",
    "\n",
    "        xb = xb.to(DEVICE)\n",
    "        o = net(xb)\n",
    "\n",
    "        os.append(o)\n",
    "\n",
    "    y = torch.cat(y)\n",
    "    o = torch.cat(os)\n",
    "\n",
    "    l = criterion(o, y).item()\n",
    "    \n",
    "    o = o.sigmoid()\n",
    "    y = (y > 0.5)*1.0\n",
    "\n",
    "    lrap = label_ranking_average_precision_score(y.cpu().numpy(), o.cpu().numpy())\n",
    "\n",
    "    o = (o > 0.5)*1.0\n",
    "\n",
    "    prec = ((o*y).sum()/(1e-6 + o.sum())).item()\n",
    "    rec = ((o*y).sum()/(1e-6 + y.sum())).item()\n",
    "    f1 = 2*prec*rec/(1e-6+prec+rec)\n",
    "\n",
    "    return l, lrap, f1, rec, prec, \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_step(x_data, y_data, net, criterion, optimizer, scaler):\n",
    "\n",
    "  x_data, y_data = x_data.to(DEVICE), y_data.to(DEVICE)\n",
    "        \n",
    "  optimizer.zero_grad()\n",
    "  output = net(x_data)\n",
    "  with torch.cuda.amp.autocast():\n",
    "    loss = criterion(output, y_data)\n",
    "  scaler.scale(loss).backward()\n",
    "  scaler.step(optimizer)\n",
    "  scaler.update()\n",
    "  \n",
    "  with torch.no_grad():\n",
    "      l = loss.item()\n",
    "\n",
    "      output = output.sigmoid()\n",
    "      y_data = (y_data > 0.5 )*1.0\n",
    "      lrap = label_ranking_average_precision_score(y_data.cpu().numpy(), output.cpu().numpy())\n",
    "\n",
    "      output = (output > 0.5)*1.0\n",
    "\n",
    "      prec = (output*y_data).sum()/(1e-6 + output.sum())\n",
    "      rec = (output*y_data).sum()/(1e-6 + y_data.sum())\n",
    "      f1 = 2*prec*rec/(1e-6+prec+rec)\n",
    "\n",
    "  return l, lrap, f1.item(), rec.item(), prec.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_epoch(epoch,net, criterion, optimizer, scheduler, scaler, train_loader, valid_loader):\n",
    "    net.train()\n",
    "    l, lrap, prec, rec, f1, icount = 0.,0.,0.,0., 0., 0\n",
    "    train_loader = tqdm(train_loader, leave = False)\n",
    "    epoch_bar = train_loader\n",
    "    scaler = scaler\n",
    "    \n",
    "    for (xb, yb) in  epoch_bar:\n",
    "        # epoch_bar.set_description(\"----|----|----|----|---->\")\n",
    "        _l, _lrap, _f1, _rec, _prec = one_step(xb, yb, net, criterion, optimizer, scaler)\n",
    "        l += _l\n",
    "        lrap += _lrap\n",
    "        f1 += _f1\n",
    "        rec += _rec\n",
    "        prec += _prec\n",
    "\n",
    "        icount += 1\n",
    "        if hasattr(epoch_bar, \"set_postfix\") and not icount%10:\n",
    "            epoch_bar.set_postfix(\n",
    "                loss=\"{:.3f}\".format(l/icount),\n",
    "                lrap=\"{:.3f}\".format(lrap/icount),\n",
    "                prec=\"{:.3f}\".format(prec/icount),\n",
    "                rec=\"{:.3f}\".format(rec/icount),\n",
    "                f1=\"{:.3f}\".format(f1/icount),\n",
    "                lr=\"{:.6f}\".format(optimizer.param_groups[0]['lr'])\n",
    "              )\n",
    "            \n",
    "    scheduler.step()\n",
    "\n",
    "    l /= icount\n",
    "    lrap /= icount\n",
    "    f1 /= icount\n",
    "    rec /= icount\n",
    "    prec /= icount\n",
    "  \n",
    "    l_val, lrap_val, f1_val, rec_val, prec_val = evaluate(net, criterion, valid_loader)\n",
    "  \n",
    "    return (l, l_val), (lrap, lrap_val), (f1, f1_val), (rec, rec_val), (prec, prec_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Train loop\n",
    "# ====================================================\n",
    "def train_loop(folds,fold):\n",
    "    \n",
    "    save_root = MODEL_ROOT/f\"{CFG.model_name}_{CFG.exp_name}/fold{CFG.trn_fold}\"\n",
    "    save_root.mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "    trn_idx = folds[folds['fold'] != fold].index\n",
    "    val_idx = folds[folds['fold'] == fold].index\n",
    "    \n",
    "    train_folds = folds.loc[trn_idx].reset_index(drop=True)\n",
    "    valid_folds = folds.loc[val_idx].reset_index(drop=True)\n",
    "    del train_folds['fold']\n",
    "    del valid_folds['fold']\n",
    "    \n",
    "    log = Logger()\n",
    "    log.open(OUTPUT_DIR + '/log.train.txt', mode='a')\n",
    "    log.write('\\n--- [START %s] %s\\n\\n' % (IDENTIFIER, '-' * 64))\n",
    "    log.write('\\t%s\\n' % COMMON_STRING)\n",
    "    log.write('\\t__file__ = %s\\n' % CFG.exp_name)\n",
    "    log.write('\\tout_dir  = %s\\n' % OUTPUT_DIR)\n",
    "    log.write('\\n')\n",
    "    # ====================================================\n",
    "    # dataset and loader\n",
    "    # ====================================================\n",
    "    \n",
    "    train_dataset = BirdClefDataset(audio_image_store,train_folds,LABEL_IDS,INV_LABEL_IDS,is_train=True)\n",
    "    \n",
    "    valid_dataset = BirdClefDataset(audio_image_store,valid_folds,LABEL_IDS,INV_LABEL_IDS,is_train=False)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, \n",
    "                              batch_size=CFG.batch_size,\n",
    "                              num_workers=CFG.num_workers,\n",
    "                              shuffle=True,\n",
    "                              pin_memory=True)\n",
    "    \n",
    "    valid_loader = DataLoader(valid_dataset,\n",
    "                              batch_size=CFG.batch_size,\n",
    "                              num_workers=CFG.num_workers,\n",
    "                              shuffle=False)\n",
    "    \n",
    "    # ====================================================\n",
    "    # scheduler \n",
    "    # ====================================================\n",
    "    def get_scheduler(optimizer):\n",
    "        if CFG.scheduler=='ReduceLROnPlateau':\n",
    "            scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=CFG.factor, patience=CFG.patience, verbose=True, eps=CFG.eps)\n",
    "        elif CFG.scheduler=='CosineAnnealingLR':\n",
    "            scheduler = CosineAnnealingLR(optimizer, T_max=CFG.T_max,eta_min=CFG.min_lr,verbose=True)\n",
    "        elif CFG.scheduler=='CosineAnnealingWarmRestarts':\n",
    "            scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=CFG.T_0, T_mult=1, eta_min=CFG.min_lr,verbose=True)\n",
    "        return scheduler\n",
    "    \n",
    "    # ====================================================\n",
    "    # model & optimizer\n",
    "    # ====================================================\n",
    "    log.write('** net setting **\\n')\n",
    "\n",
    "    log.write('** start training here! **\\n')\n",
    "    log.write('   is_mixed_precision = %s \\n' % str(True))\n",
    "    log.write('   batch_size = %d\\n' % (CFG.batch_size))\n",
    "    log.write('   experiment = %s\\n' % str(CFG.exp_name))\n",
    "    def message():\n",
    "        text = \\\n",
    "            'E:%.1f | ' % (epoch) + \\\n",
    "            'L:%.5f  %.4f | ' % (l, l_val) + \\\n",
    "            'P:%.3f  %.3f | ' % (prec,prec_val) + \\\n",
    "            'R:%.3f  %.3f | ' % (rec,rec_val) + \\\n",
    "            'F:%.3f  %.3f | ' % (f1,f1_val) + \\\n",
    "            'Lr:%.3f  %.3f | ' % (lrap,lrap_val)\n",
    "\n",
    "        return text\n",
    "              \n",
    "    if CFG.checkpoint:\n",
    "        print('Loading checkpoint')\n",
    "        ckpt = torch.load(r\"Birdcall\\models\\resnest50_augs_mix3_3_col_cor\\fold[0]\\resnest50_fold0_e59_augs_mix3_3_col_cor.pth\") # load your last pth file here and change the last_epoch value in get_scheduler()\n",
    "        net = get_model(CFG.model_name)\n",
    "        net.load_state_dict(ckpt['net'])\n",
    "        net.to(DEVICE)\n",
    "#     net = Net(CFG.model_name,pretrained=True)\n",
    "        optimizer = Adam(net.parameters(), lr=CFG.base_lr, amsgrad=False)\n",
    "        optimizer.load_state_dict(ckpt['optimizer'])\n",
    "        \n",
    "        scheduler = get_scheduler(optimizer)\n",
    "        scheduler.load_state_dict(ckpt['scheduler'])\n",
    "        \n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "        # Stochastic Weighted Averaging\n",
    "    #     swa_model = AveragedModel(net)\n",
    "    #     swa_scheduler = SWALR(optimizer, swa_lr=CFG.swa_lr)\n",
    "\n",
    "        epochs_bar = tqdm(list(range(CFG.epochs)), leave=False)\n",
    "        # FP-16\n",
    "        scaler = torch.cuda.amp.GradScaler()\n",
    "        e = ckpt['epoch']\n",
    "        print(f\"Epoch:{e} - Loss:{ckpt['loss']} - F1:{ckpt['f1']} - F1_val:{ckpt['f1_val']} - LR{ckpt['scheduler']}\")\n",
    "        for epoch  in epochs_bar:\n",
    "            epoch = epoch+ e+1 \n",
    "            epochs_bar.set_description(f\"[EPOCH {epoch:02d}]\")\n",
    "            net.train()\n",
    "\n",
    "            (l, l_val), (lrap, lrap_val), (f1, f1_val), (rec, rec_val), (prec, prec_val) = one_epoch(\n",
    "                epoch,\n",
    "                net=net,\n",
    "                criterion=criterion,\n",
    "                optimizer=optimizer,\n",
    "                scheduler=scheduler,\n",
    "                scaler=scaler,\n",
    "                train_loader=train_loader,\n",
    "                valid_loader=valid_loader,\n",
    "              )\n",
    "\n",
    "            epochs_bar.set_postfix(\n",
    "            loss=\"({:.6f}, {:.6f})\".format(l, l_val),\n",
    "            prec=\"({:.3f}, {:.3f})\".format(prec, prec_val),\n",
    "            rec=\"({:.3f}, {:.3f})\".format(rec, rec_val),\n",
    "            f1=\"({:.3f}, {:.3f})\".format(f1, f1_val),\n",
    "            lrap=\"({:.3f}, {:.3f})\".format(lrap, lrap_val),\n",
    "            lr=\"({:.5f})\".format(optimizer.param_groups[0]['lr'])\n",
    "            )\n",
    "\n",
    "            print(\n",
    "                \"[{epoch:02d}] L: {loss} Lr: {lrap} F1: {f1} R: {rec} P: {prec} LR:{lr}\".format(\n",
    "                    epoch=epoch,\n",
    "                    loss=\"({:.6f}, V:{:.6f})\".format(l, l_val),\n",
    "                    prec=\"({:.3f}, V:{:.3f})\".format(prec, prec_val),\n",
    "                    rec=\"({:.3f}, V:{:.3f})\".format(rec, rec_val),\n",
    "                    f1=\"({:.3f}, V:{:.3f})\".format(f1, f1_val),\n",
    "                    lrap=\"({:.3f}, V:{:.3f})\".format(lrap, lrap_val),\n",
    "                    lr=\"({:.5f})\".format(optimizer.param_groups[0]['lr'])\n",
    "                )\n",
    "            )\n",
    "            log.write(message() + '\\n')\n",
    "            if CFG.save:\n",
    "                torch.save({'net': net.state_dict(), \n",
    "                          'optimizer': optimizer.state_dict(), \n",
    "                          'scheduler': scheduler.state_dict(), \n",
    "                          'epoch': epoch,\n",
    "                          'loss':l,\n",
    "                          'f1':f1, \n",
    "                          'f1_val':f1_val\n",
    "                        },\n",
    "                          OUTPUT_DIR+f'/{CFG.model_name}_fold{fold}_e{epoch}_cont_{CFG.exp_name}.pth')\n",
    "    else:\n",
    "        net = get_model(CFG.model_name).to(DEVICE)\n",
    "        optimizer = Adam(net.parameters(), lr=CFG.base_lr, amsgrad=False)\n",
    "\n",
    "        scheduler = get_scheduler(optimizer)\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "        # Stochastic Weighted Averaging\n",
    "    #     swa_model = AveragedModel(net)\n",
    "    #     swa_scheduler = SWALR(optimizer, swa_lr=CFG.swa_lr)\n",
    "\n",
    "        epochs_bar = tqdm(list(range(CFG.epochs)), leave=False)\n",
    "        # FP-16\n",
    "        scaler = torch.cuda.amp.GradScaler()\n",
    "        for epoch  in epochs_bar:\n",
    "            epochs_bar.set_description(f\"[EPOCH {epoch:02d}]\")\n",
    "            net.train()\n",
    "\n",
    "            (l, l_val), (lrap, lrap_val), (f1, f1_val), (rec, rec_val), (prec, prec_val) = one_epoch(\n",
    "                epoch,\n",
    "                net=net,\n",
    "                criterion=criterion,\n",
    "                optimizer=optimizer,\n",
    "                scheduler=scheduler,\n",
    "                scaler=scaler,\n",
    "                train_loader=train_loader,\n",
    "                valid_loader=valid_loader,\n",
    "              )\n",
    "\n",
    "            epochs_bar.set_postfix(\n",
    "            loss=\"({:.6f}, {:.6f})\".format(l, l_val),\n",
    "            prec=\"({:.3f}, {:.3f})\".format(prec, prec_val),\n",
    "            rec=\"({:.3f}, {:.3f})\".format(rec, rec_val),\n",
    "            f1=\"({:.3f}, {:.3f})\".format(f1, f1_val),\n",
    "            lrap=\"({:.3f}, {:.3f})\".format(lrap, lrap_val),\n",
    "            )\n",
    "\n",
    "            print(\n",
    "                \"[{epoch:02d}] L: {loss} Lr: {lrap} F1: {f1} R: {rec} P: {prec}\".format(\n",
    "                    epoch=epoch,\n",
    "                    loss=\"({:.6f}, V:{:.6f})\".format(l, l_val),\n",
    "                    prec=\"({:.3f}, V:{:.3f})\".format(prec, prec_val),\n",
    "                    rec=\"({:.3f}, V:{:.3f})\".format(rec, rec_val),\n",
    "                    f1=\"({:.3f}, V:{:.3f})\".format(f1, f1_val),\n",
    "                    lrap=\"({:.3f}, V:{:.3f})\".format(lrap, lrap_val),\n",
    "                )\n",
    "            )\n",
    "            log.write(message() + '\\n')\n",
    "            if CFG.save:\n",
    "                torch.save({'net': net.state_dict(), \n",
    "                          'optimizer': optimizer.state_dict(), \n",
    "                          'scheduler': scheduler.state_dict(), \n",
    "                          'epoch': epoch,\n",
    "                          'loss':l,\n",
    "                          'f1':f1, \n",
    "                          'f1_val':f1_val\n",
    "                        },\n",
    "                          OUTPUT_DIR+f'/{CFG.model_name}_fold{fold}_e{epoch}_{CFG.exp_name}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    if CFG.train:\n",
    "        for fold in range(CFG.n_fold):\n",
    "            if fold in CFG.trn_fold:\n",
    "                train_loop(folds,fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
